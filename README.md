<h1 align="center">Hey there, I'm Ninaad Sawant! üëã</h1>
<p align="center">
  Data Engineer | Python, Pyspark, Scala, SQL, Kafka | ETL, ELT, Airflow | AWS, Azure, Snowflake | Data modeling, Visualization
</p>


## üë®‚Äçüíª About Me

- üöÄ Recent graduate, Master of Science in Computer Science at **Clark University** (May 2025).
- üíº Previously worked at **Infosys** as a Digital Specialist Engineer, focusing on:
  - **Data Engineering** (ETL pipelines, HDFS, Amazon S3, Elasticsearch)
  - **Big Data Processing** (Scala Spark, PySpark)
  - **API Development & Integration** (Java Spring Boot, Python)
  - **CI/CD** (Jenkins) & **Automation** (Apache Airflow, Control-M)
- üí° Keen interest in **Big Data**, **Advanced Analytics** and **Machine Learning**, bridging data engineering with predictive modeling.
- üõ†Ô∏è Driven by building scalable, robust solutions for data pipelines and microservices.
- üåç Based in Worcester, MA - open to collaborating on projects globally.


## üí° Key Skills & Technologies

**Programming & Scripting:**
- **Languages**: Java, Python, Scala, SQL
- **Shell Scripting** Unix, Bash

**Data Engineering:**
- **Frameworks**: Spark (Scala/PySpark), Hadoop
- **Data Analytics/ Engineering:** Pyspark, Scala, ETL/ ELT, HiveQL, Spark SQL, Pig, Sqoop, Kafka, Pandas, Numpy
- **Data Stores**: HDFS, Elasticsearch, MySQL, PostgreSQL, MongoDB, Hive
- **ETL Tools**: Apache Airflow, Control-M, AWS Glue, Azure Data Factory, DBT

**Cloud Computing:**
- **AWS**: S3, RedShift, Glue, IAM, Crawler, QuickSight, EC2
- **Azure**: Data Factory, Synapse, Databricks, ADLS Gen2
- **GCP**: BigQuery, Cloud Storage

**Machine Learning & Analytics:**
- **Libraries**: Scikit-learn, Pandas, NumPy  
- **Visualization**: Tableau, Power BI, Matplotlib, Plotly

**API & Backend Development:**
- **RESTful Services**: Java Spring Boot, Python (Flask/FastAPI)
- **Testing**: Postman

**Certifications:**
-  AWS Certified Data Engineer - Associate
-  AWS Certified Cloud Practitioner


## üíº Professional Experience

### Infosys Limited (Pune, India)  
**Digital Specialist Engineer (May 2021 - Nov 2023)**  
- Designed and deployed over 25 ETL pipelines using PySpark and Scala, each capable of processing more than 10 million records daily, across HDFS, Amazon S3, and Elasticsearch, collectively improving data throughput by 33\%.
- Designed and maintained real-time data ingestion pipelines using Apache Kafka, enabling near-instant event processing and reducing data latency by 40\%.
- Wrote and optimized over 150 complex SQL queries involving multi-table joins, window functions, and CTEs, reducing report generation time by 40\% and supporting faster decision-making across analytics teams.
- Queried large-scale distributed datasets using HiveQL and Spark SQL to troubleshoot production issues, reducing average issue resolution time by 35\% and improving data pipeline up-time.
- Partnered with data ingestion team to migrate and standardize around 1 billion records from Google BigQuery to HDFS, contributing to the construction of a scalable data lake.
- Developed scalable and secure RESTful APIs using Python and Java Spring Boot connecting clients with the relevant datasets, handling over 50,000 requests per day.
- Streamlined API testing using Postman and implemented data validation checks to ensure software and data reliability; conducted API performance tuning, reducing response times by 83\%.
- Implemented CI/CD pipelines with Jenkins and Git to ensure smooth and reliable deployment of services and version control.
- Automated more than 25 ETL pipelines using Apache Airflow, scheduling the jobs as per the clients requirements, reducing manual intervention by 99\% and enhancing data pipeline reliability.
- Collaborated with cross-functional teams and stakeholders in weekly Agile meetings to define data pipelines, data modeling and API functionality, enhancing SLA compliance by 90\%.
- Interviewed and mentored 6 new trainees and led a 2-week training on project requirements and workflows, enabling rapid integration into the team and ensuring no impact on project timelines.
- Monitored 25+ critical ETL pipelines in production, performing root cause analysis on failures and coordinating with relevant teams for resolution, ensuring timely support and reducing data issues by 97\%.
- Conducted regular code reviews to ensure test case coverage, coding standards, and compliance with security best practices.
- Documented workflows and project progress using Confluence to ensure transparency with stakeholders and engineering teams, enabling seamless handovers and project continuity.

### Bloombit (Goa, India)  
**Web Developer, Intern (Aug 2020 - Nov 2020)**  
- Engineered scalable software components using JavaScript and RESTful APIs, integrating secure JWT-based authentication and improving system reliability and response time by 35\% across user-facing platforms.
- Delivered client solutions by implementing scalable support features, boosting user inquiry resolution efficiency by 50\%.



## üî¨ Projects
  
1. **Tableau Sales Analytics Dashboard**
   - Built a Tableau dashboard that visualized over 10,000 sales transactions across 50 U.S. states, resulting in a 27% increase in
insight visibility through interactive filters, Year-over-Year KPIs, and segment-level breakdowns.
2. **Snowflake Revenue Analytics Pipeline**
   - Built a Snowflake data warehouse using Medallion Architecture (stage-clean-consumption) with a star schema (7 dimensions, 1
fact), generating 20 business KPIs for revenue, order trends, and restaurant performance.
3. **Azure ADF Synapse Medallion Pipeline**
   - Built a scalable Azure data pipeline ingesting 75k+ API records using Data Factory, Databricks, and Synapse; optimized ETL
workflows, reducing processing time by 35% and improving Power BI load times by 25%.
  
[Many more...](https://github.com/NinaadSawant23?tab=repositories)

## üì´ Contact & Connect

- **Email**: ninaadsawant23@gmail.com  
- **LinkedIn**: [Ninaad-Sawant](https://www.linkedin.com/in/ninaadsawant/)
- **Phone**: 774-420-0444  



<p align="center">Thanks for visiting! Let's build something amazing together. üõ†Ô∏è</p>
